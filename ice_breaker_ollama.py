from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from dotenv import load_dotenv
 
if __name__ == "__main__":
    load_dotenv()
    llm = ChatOpenAI(model="gpt-4.1", temperature=0)
    # llm = ChatOllama(model="llama3", temperature=0)
    # llm = ChatOllama(model="mistral", temperature=0)

    prompt = ChatPromptTemplate.from_template(
        "Tell me two jokes about {topic}")

    chain = prompt | llm | StrOutputParser()

    result = chain.invoke({"topic": "Write a song about a cat"})

    print(result)
    # print(f"Generated by: {llm.model}")
