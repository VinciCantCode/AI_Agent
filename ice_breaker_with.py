from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from dotenv import load_dotenv
from tools.tools import get_profile_url_tavily

def ice_breaker_with(name: str):

    linkedin_url=get_profile_url_tavily(query=name)
    print(f"Tavily search results for '{name}':")
    print("=" * 50)
    print(linkedin_url)
    print("=" * 50)

    llm = ChatOpenAI(model="gpt-4.1", temperature=0)
    # llm = ChatOllama(model="llama3", temperature=0)
    # llm = ChatOllama(model="mistral", temperature=0)

    prompt = ChatPromptTemplate.from_template(
        """
        Based on the following information search results for {name}, create: 
        1. You go to search this {name} in the Linkedin website.
        2. And tell me 2 rules about how to ice break with them including their work and education background.
        
        Search results: {search_results}
        """
    )

    chain = prompt | llm | StrOutputParser()

    result = chain.invoke({"name": name, "search_results": linkedin_url})

    print(result)
    # print(f"Generated by: {llm.model}")

if __name__ == "__main__":
    load_dotenv()
    ice_breaker_with("HongQing Lin study in FDU")